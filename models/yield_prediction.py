# -*- coding: utf-8 -*-
"""yield_prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KFwpk5dowFMMIixk3es787kyicltqRPa
"""

# Importing Libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px

import warnings
warnings.filterwarnings('ignore')

df = pd.read_csv("crop_yield.csv")

df.head()

df.shape

df.describe()

df.isna().sum()

df.dtypes

#unique crops
df['Crop'].unique()

df['Crop'].value_counts()

df.info()

from sklearn.preprocessing import LabelEncoder

label_encoder = LabelEncoder()
df['crop_encoded'] = label_encoder.fit_transform(df['Crop'])
df['season_encoded'] = label_encoder.fit_transform(df['Season'])
df['state_encoded'] = label_encoder.fit_transform(df['State'])

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()

df['Crop_Year_scaled'] = scaler.fit_transform(df[['Crop_Year']])
df['Area_scaled'] = scaler.fit_transform(df[['Area']])
df['Production_scaled'] = scaler.fit_transform(df[['Production']])
df['Annual_Rainfall_scaled'] = scaler.fit_transform(df[['Annual_Rainfall']])
df['Fertilizer_scaled'] = scaler.fit_transform(df[['Fertilizer']])
df['Pesticide_scaled'] = scaler.fit_transform(df[['Pesticide']])
df['Yield_scaled'] = scaler.fit_transform(df[['Yield']])

df.columns

df.shape

features = [ 'Crop_Year','crop_encoded','state_encoded','Fertilizer','Annual_Rainfall','Production']
target   = [ 'Yield' ]

X = df.loc[: , features]
Y = df.loc[: , target]

from sklearn.model_selection import train_test_split
X_train , X_test , Y_train , Y_test = train_test_split(X,Y,test_size = 0.4,random_state = 20)

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
Y_train = scaler.fit_transform(Y_train)
X_test = scaler.fit_transform(X_test)
Y_test = scaler.fit_transform(Y_test)

!pip install --upgrade xgboost scikit-learn

import xgboost as xgb
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# Define the XGBoost regressor
xgb_reg = xgb.XGBRegressor(objective='reg:squarederror')

# Train the model
xgb_reg.fit(X_train, Y_train)

# Make predictions on the test set
y_pred = xgb_reg.predict(X_test)

# Evaluate the model
mse = mean_squared_error(Y_test, y_pred)
mae = mean_absolute_error(Y_test, y_pred)
r2 = r2_score(Y_test, y_pred)

print("Mean Squared Error:", mse)
print("Mean Absolute Error:", mae)
print("R-squared (R2):", r2)

import pickle
# Dump the trained Naive Bayes classifier with Pickle
XR_pkl_filename = 'XGB_Regressor.pkl'
# Open the file to save as pkl file
XR_Model_pkl = open(XR_pkl_filename, 'wb')
pickle.dump(xgb_reg, XR_Model_pkl)
# Close the pickle instances
XR_Model_pkl.close()

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

model_lr = LinearRegression()

model_lr.fit(X_train, Y_train)

y_pred = model_lr.predict(X_test)

mse = mean_squared_error(Y_test, y_pred)
mae = mean_absolute_error(Y_test, y_pred)
r2 = r2_score(Y_test, y_pred)

print("Mean Squared Error:", mse)
print("Mean Absolute Error:", mae)
print("R-squared (R2):", r2)

features = [ 'Crop_Year_scaled','crop_encoded', 'state_encoded','Area_scaled','Production_scaled','Annual_Rainfall_scaled','Fertilizer_scaled']
target   = [ 'Yield_scaled' ]

X = df.loc[: , features]
Y = df.loc[: , target]

from sklearn.model_selection import train_test_split
X_train , X_test , Y_train , Y_test = train_test_split(X,Y,test_size = 0.4,random_state = 20)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping


X_train_ls = X_train.values.reshape((X_train.shape[0], 1, X_train.shape[1]))
X_test_ls = X_test.values.reshape((X_test.shape[0], 1, X_test.shape[1]))
Y_train_ls  = Y_train.values

print(X_train_ls.shape,X_train_ls[0])

model_ls = Sequential([
    LSTM(units=100, input_shape=(X_train_ls.shape[1], X_train_ls.shape[2])),
    Dense(units=1)
])

optimizer = Adam(learning_rate=0.001)
model_ls.compile(optimizer=optimizer, loss='mean_absolute_error')
model_ls.summary()

early_stopping = EarlyStopping(patience=5, restore_best_weights=True)

history = model_ls.fit(X_train_ls, Y_train_ls, epochs=150, batch_size=32, validation_split=0.2,
                    callbacks=[early_stopping], verbose=1)

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score


Y_pred = model_ls.predict(X_test_ls)

mse = mean_squared_error(Y_test, Y_pred)
r2 = r2_score(Y_test, Y_pred)
mae = mean_absolute_error(Y_test, Y_pred)

print("Mean Absolute Error:", mae)
print("R-squared (R2):", r2)
print("Mean Squared Error:", mse)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler

model_lstm = Sequential([
    Bidirectional(LSTM(units=200, return_sequences=True, input_shape=(X_train_ls.shape[1], X_train_ls.shape[2]))),
    Dropout(0.2),
    LSTM(units=100),
    Dropout(0.2),
    Dense(units=1)
])

optimizer = Adam(learning_rate=0.001)
model_lstm.compile(optimizer=optimizer, loss='mean_squared_error')
model_lstm.summary()

early_stopping = EarlyStopping(patience=10, restore_best_weights=True)

history = model_lstm.fit(X_train_ls, Y_train_ls, epochs=200, batch_size=32, validation_split=0.2,
                    callbacks=[early_stopping], verbose=1)

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score


Y_pred = model_lstm.predict(X_test_ls)

mse = mean_squared_error(Y_test, Y_pred)
r2 = r2_score(Y_test, Y_pred)
mae = mean_absolute_error(Y_test, Y_pred)

print("Mean Absolute Error:", mae)
print("R-squared (R2):", r2)
print("Mean Squared Error:", mse)

from tensorflow.keras.models import Sequential

# Save the LSTM model
model_lstm.save("lstm_model.h5")  # Saved as .h5 format, which is the standard format for Keras models

# Load the LSTM model
from tensorflow.keras.models import load_model
loaded_lstm_model = load_model("lstm_model.h5")